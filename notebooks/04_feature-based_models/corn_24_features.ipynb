{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vc-XiFpM1ufp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, cohen_kappa_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0emsKc010jH"
      },
      "outputs": [],
      "source": [
        "class FeatureCORN(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes=8):\n",
        "        super(FeatureCORN, self).__init__()\n",
        "        self.num_tasks = num_classes - 1\n",
        "\n",
        "        self.classifiers = nn.ModuleList([\n",
        "            nn.Linear(input_dim, 1) for _ in range(self.num_tasks)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        logits = []\n",
        "        for classifier in self.classifiers:\n",
        "            logits.append(classifier(x))\n",
        "        return torch.cat(logits, dim=1)\n",
        "\n",
        "def corn_label_encoding(y, num_classes=8):\n",
        "\n",
        "    pass\n",
        "\n",
        "def predict_corn_rank(logits):\n",
        "\n",
        "    # 1. Convert logits to conditional probabilities P(y > k | y > k-1)\n",
        "    cond_probs = torch.sigmoid(logits)\n",
        "\n",
        "    # 2. Compute unconditional cumulative probabilities via Chain Rule\n",
        "    # We initialize cum_probs with 1s (P(y > -1) = 1)\n",
        "    cum_probs = torch.ones(logits.size(0), logits.size(1) + 1).to(logits.device)\n",
        "\n",
        "    # cum_probs[:, 0] is the probability of being > -1 (always 1.0)\n",
        "    # cum_probs[:, 1] is P(y>0) = P(y>0|y>-1) * 1.0\n",
        "    # cum_probs[:, 2] is P(y>1) = P(y>1|y>0) * P(y>0)\n",
        "\n",
        "    for k in range(logits.size(1)):\n",
        "        cum_probs[:, k+1] = cond_probs[:, k] * cum_probs[:, k]\n",
        "\n",
        "    # 3. Sum cumulative probabilities (excluding the dummy > -1 column) to get rank\n",
        "    # We sum columns 1 to End.\n",
        "    # Expected Rank = Sum(P(y > 0) + P(y > 1) + ... + P(y > K-1))\n",
        "    pred_rank = torch.sum(cum_probs[:, 1:], dim=1)\n",
        "    return torch.round(pred_rank).detach().cpu().numpy().astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBNvu1h-1-YA"
      },
      "outputs": [],
      "source": [
        "target_col = 'label' if 'label' in df.columns else 'labels'\n",
        "\n",
        "X = df.drop(columns=[target_col]).values.astype(np.float32)\n",
        "y = df[target_col].values.astype(np.int64)\n",
        "num_classes = 8\n",
        "input_dim = X.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmLwmW5I2Az-",
        "outputId": "e87bb626-3c3e-42c2-beec-7073facc48ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Feature-CORN (PyTorch) on 24 features...\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "results = {'MAE': [], 'RMSE': [], 'QWK': []}\n",
        "fold = 1\n",
        "\n",
        "print(f\"Starting Feature-CORN (PyTorch) on {input_dim} features...\")\n",
        "print(\"-\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suYuScR_2EU2",
        "outputId": "b82c4573-66f0-4c9e-8bef-aa10332bd31f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1: QWK = 0.7480 | MAE = 0.6711 | RMSE = 1.0066\n",
            "Fold 2: QWK = 0.7534 | MAE = 0.7105 | RMSE = 1.0131\n",
            "Fold 3: QWK = 0.7785 | MAE = 0.6316 | RMSE = 0.9272\n",
            "Fold 4: QWK = 0.7773 | MAE = 0.6432 | RMSE = 0.9292\n",
            "Fold 5: QWK = 0.7495 | MAE = 0.7048 | RMSE = 0.9800\n"
          ]
        }
      ],
      "source": [
        "for train_index, test_index in skf.split(X, y):\n",
        "    X_train_fold, X_test_fold = X[train_index], X[test_index]\n",
        "    y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_fold = scaler.fit_transform(X_train_fold)\n",
        "    X_test_fold = scaler.transform(X_test_fold)\n",
        "\n",
        "    X_test_t = torch.tensor(X_test_fold)\n",
        "\n",
        "    model = FeatureCORN(input_dim, num_classes)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.05, weight_decay=0)\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    model.train()\n",
        "    epochs = 1500\n",
        "\n",
        "    X_train_t_all = torch.tensor(X_train_fold)\n",
        "    y_train_t_all = torch.tensor(y_train_fold)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        total_loss = 0\n",
        "\n",
        "        for k in range(num_classes - 1):\n",
        "            # Condition: We only train on essays where true label > k-1\n",
        "            # For k=0: y > -1 (All data)\n",
        "            # For k=1: y > 0 (Exclude Novice Low)\n",
        "            mask = y_train_t_all > (k - 1)\n",
        "\n",
        "            if mask.sum() == 0: continue\n",
        "\n",
        "            X_subset = X_train_t_all[mask]\n",
        "            y_subset = y_train_t_all[mask]\n",
        "\n",
        "\n",
        "            binary_targets = (y_subset > k).float().view(-1, 1)\n",
        "\n",
        "\n",
        "            logits_k = model.classifiers[k](X_subset)\n",
        "\n",
        "            loss_k = loss_fn(logits_k, binary_targets)\n",
        "            total_loss += loss_k\n",
        "\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_logits = model(X_test_t)\n",
        "        y_pred = predict_corn_rank(test_logits)\n",
        "\n",
        "\n",
        "    mae = mean_absolute_error(y_test_fold, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test_fold, y_pred))\n",
        "    qwk = cohen_kappa_score(y_test_fold, y_pred, weights='quadratic')\n",
        "\n",
        "    results['MAE'].append(mae)\n",
        "    results['RMSE'].append(rmse)\n",
        "    results['QWK'].append(qwk)\n",
        "\n",
        "    print(f\"Fold {fold}: QWK = {qwk:.4f} | MAE = {mae:.4f} | RMSE = {rmse:.4f}\")\n",
        "    fold += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xq4TKep12H8X",
        "outputId": "2bd867c2-56f8-4ec1-8916-18517a650cc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------\n",
            "FINAL RESULTS (Feature-CORN):\n",
            "MAE: 0.6722 ± 0.0317\n",
            "RMSE: 0.9712 ± 0.0368\n",
            "QWK: 0.7614 ± 0.0136\n"
          ]
        }
      ],
      "source": [
        "print(\"-\" * 60)\n",
        "print(\"FINAL RESULTS (Feature-CORN):\")\n",
        "for metric, values in results.items():\n",
        "    print(f\"{metric}: {np.mean(values):.4f} ± {np.std(values):.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
